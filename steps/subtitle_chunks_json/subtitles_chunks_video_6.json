[
  {
    "start": "00:00:00.000000",
    "end": "00:00:46.069000",
    "text": "in an earli video we have seen the convolutional networks and the basic operation in this video what we actually introducing here is residual networks which is to this day many years after the introduction remain one of the main used architectures for feature extraction and not only as a basic component of many more advanced cnc architectures and that are doing more complicated tasks such like object detection semantic segmentation and others that we will see in another in another video so the history ifyou like of their introduction"
  },
  {
    "start": "00:00:46.069000",
    "end": "00:01:30.560000",
    "text": "you know started around 2015 where people realized that its not really possible to extend the socalled architectures of the time let say the vgg architecture weve seen the varchitecture on on a different uvideo earlier in this in this actually topic over here where we have se we have seen the sort of architecture of the v16 network and what was actually happening then and now that we understand  a couple of things about back propagation"
  },
  {
    "start": "00:01:30.560000",
    "end": "00:01:32.429000",
    "text": "the gradient had a lot of problems toflow all the way to the input of the network and the u sort of bottlenecks that were actually generated created a significant problems in the training of these architectures"
  },
  {
    "start": "00:01:32.429000",
    "end": "00:02:13.560000",
    "text": "so around 2015 a researcher at microsoft you know found  a solution on how to enable that gradient to flow freely in in  a much deeper architectures such as the ones that we will see in — a moment and the this gave their the name resid because it in that architecture we implement what we call resid unitthats my unit which ill abstract with the letter f1 so the input to the so ill use a bit different terminology from what i was used kind of earlier so ill be calling set of x ill be calling it y0"
  },
  {
    "start": "00:02:13.560000",
    "end": "00:03:00.239000",
    "text": "i could have used it also x0 but in my not over here i have the this as yuz okayso the yz goes into a block that will consist of one or more convolutional kind layers and this is why we call it residuals we take the input and add it with a unit gain into to the output to the output"
  },
  {
    "start": "00:03:00.239000",
    "end": "00:03:16.200000",
    "text": "okay so to form what we call now a y1 the 1 is being added into again with exactly the sameoutput j2 and the 2 is similarlyfinal ny3 output okay so this is the kind of we had convolutional layers max pool layers and so nonlinear evidently over here but we never had this kind of skipover connection as we call it okay"
  },
  {
    "start": "00:03:16.200000",
    "end": "00:04:20.919000",
    "text": "so i want to just go ahead and write now the expression of each of these blocks with respect to the input so i hope you agree that this is exactly what each of these blocks is implement okay so we have the fi of y ius one plus the y – x – one in each of these so if i may write down these equations for lets say pety2 the y2 itself is fs2 of yu1y1 and the x1 is fub1 of yu0y0"
  },
  {
    "start": "00:04:20.919000",
    "end": "00:04:38.840000",
    "text": "these are the three equations for each of the three blocks that i have here and what i want to do now is i want to start replacing the yi2 and yo1 into the equation j3 because i want to write down the equation the form of the y3 as a function of only the y0 and the two functions that are involved in the blocks always so all right im sorry f3 ofs2 of ya1 fyi 1yup okay so i just replace it y2 with it equal and now i can replacenow let me write it over here because i just need a long line to replace it to make the final replacement"
  },
  {
    "start": "00:04:38.840000",
    "end": "00:04:45.120000",
    "text": "so it is f3 of f2 now im going to replace the f1 of s1 with its equal to obtain the finalexpression and this is now the second squarebracket okay so it is really this bracket over here plus i have fs2 of s1 of z0y0  fub1 of yuy okand write its equivalent that we just based on this equation"
  },
  {
    "start": "00:04:45.120000",
    "end": "00:06:10.589000",
    "text": "and that kind of replotteting or redraw drawing of this kind architecture will help me kinda understand  a couple of things about the advantages and why they solve the problem of gradient flow throughout the network okay so i am going to start so im dividing this into two parts i am going to first draw the long part over here"
  },
  {
    "start": "00:06:10.589000",
    "end": "00:07:21.120000",
    "text": "this f3 expression here at the bottom so i am going to take this accepts as input y0 that is the only output in thisdiagram so y0 is going into the functionf1 f1 we are adding now the function they zin it okay so thats basically this term all right so then we take the fsm2 of this term and what we do is we add for this fsm2 we add this term over here f1 y 0 y0 so we add to itanother block involving the functionf1 okay so this is basically my f3"
  },
  {
    "start": "00:07:21.120000",
    "end": "00:07:32.550000",
    "text": "so if i am acircle if ia this a will be available over here okay so we have now finished with the plotting of the first term and now lets look at the second term so the second term is simply fs2 of y1y0y0 so i am going to go againline so im going to just take again fs1 of j0y0 and that thing over here is the pointb however this so this is basically b let me throw it overhere to b"
  },
  {
    "start": "00:07:32.550000",
    "end": "00:08:00.589000",
    "text": "now what we have is over because we see here three things being involved a b and c so this isc and then b and c are added to and this will actually be my j3 and now that we have this kind of diagram we actually can make some really nice conclusions outof it as you can see the gradient in the backward pass so the point number one i want to mention is about the gradient flowso"
  },
  {
    "start": "00:08:00.589000",
    "end": "00:08:20.510000",
    "text": "you can see the gradient flow in the backward pass during back propagation now has  a diverse set of paths and to actually fly all the way to the inputlets say it has this path that simply just follows all the way to the input yz"
  },
  {
    "start": "00:08:20.510000",
    "end": "00:08:20.510000",
    "text": "the other path that goes through this f1 to go to the input this path through f2 and f the concatenation f2 and and fub1 or via this skip connection to go to f0 and so on and so on so what we see here is we have a  a  a because this is what i will call it because these are what we have used as s of of gates okay for varing depth so thats kind of important earlier what our had"
  },
  {
    "start": "00:08:20.510000",
    "end": "00:09:03.440000",
    "text": "this path through ff2 and without those kind of skip connections we had simply f1 con with two3 in the socal lets say v architecture so here we had a  back propagation that it was involving just  a single trajectory and of course – that is not reallyobservations that led to some kind of leveling of the performance of these earlier kindof architectures"
  },
  {
    "start": "00:09:03.440000",
    "end": "00:09:03.440000",
    "text": "as the number of layers were being added up in this kind  we are effectively implement what is actually known as highway networks and those highway highways that we creating for the gradient empirically has shown that we are actually can go much much deeper so well see now some depth typical depths that we experience in we we have in a resent architect"
  },
  {
    "start": "00:09:03.440000",
    "end": "00:10:27.509000",
    "text": "in – — a moment the second aspect of that is a bit morenuanced and it has to do with what we call an ensamplearning so in this kind of ensemble learning architecture what we see is we see u the concatenation the the combination of three predictors here three main prediction architectures each of those predictors has a varying kindof functionality so we see  a"
  },
  {
    "start": "00:10:27.509000",
    "end": "00:12:41.629000",
    "text": "we see another predictor which call b and another predictor that we call c and what we see at the output are the kind of combination of those simply i mean if you are familiarwith ample kind of methods which ill provide some kindof background in a moment we are adding the individual prediction results given the input jz at the to to obtain our final prediction output the socalled yu3 hat okay and so thats ample methods have proven in the field to be  a very powerful approach in solving"
  },
  {
    "start": "00:12:41.629000",
    "end": "00:00:-1.000000",
    "text": "you know complex kind of tasks and in fact some methods are being used both for structure and unstructured data and in the structure kind of data field you have methods such as gradient boostingand so on providing some real stateoftheart results today so a few words about ample methods is arguably  a parenthesis but i think its a kind of worthwhile sort of discussing"
  },
  {
    "start": "00:00:-1.000000",
    "end": "00:12:41.629000",
    "text": "a little bit about enseque methodso there are various asample methods but i think  a common denominator for many of them  is that the prediction why hat that we get from the socalled ensample also known as committeemethods where we for form why heat committee is simply the averagelet me call it 1 capital k of the summation from small letter k is equal to 1 to capital k"
  },
  {
    "start": "00:12:41.629000",
    "end": "00:14:36.360000",
    "text": "where capital q is the number of predictors that we have here we had three in the rest net architecture of yahay subk so the premise of emme method is that we dont necessarily to have the single server bullet that will solve the very complicated kind of task of us that we have in front of us but"
  },
  {
    "start": "00:14:36.360000",
    "end": "00:14:40.990000",
    "text": "a number of what we call the socalled weakpredictors that it will u not perform individually quite well but on aggregatethey will actually perform much better that and that is really the premise of that"
  },
  {
    "start": "00:14:40.990000",
    "end": "00:15:26.199000",
    "text": "and you know one parallel architecture with have in the earlier method that we call the rest net is kinda resembles that kindof architecture because we have some kind decomposition combination of these weak predictions the socalled abs and css that i have explained earlier so the in sample methods in general we have"
  },
  {
    "start": "00:15:26.199000",
    "end": "00:16:02.240000",
    "text": "we can consider performance wise to consist from in somewhere in between two bounds so the lower bound the socal lower performance bound is obtained evidently when youre you have very correlated predictions and if you are not able to randomize the operation of each of these predictors somehow we are going to exhibit this kindof lower bound where either you form a committee or not you get exactly the same performance its just like the analogy or the equivalent analogy i would like to sorting share sh is there  a committee of lets say a human committee of human experts"
  },
  {
    "start": "00:16:02.240000",
    "end": "00:16:33.480000",
    "text": "but each expert went to exactly that school studied exactly the samefield had exactly the same university professors and they are actually now called to solve the problem and guess what each one of them is actually offering exactly the same view well thats basically where the point where you experiencing a lower performance bound and the upper performance bound is  a bit more nuanced a bit more complicated to kindofcome with but the best performance what we can actually get i think its better understood with an analogy you dont expect every committee member to not makemistakes"
  },
  {
    "start": "00:16:33.480000",
    "end": "00:17:00.350000",
    "text": "they will make mistakes but what you want to do is to have a committee that they dont make the same mistake at the same time so the socalled uncorrelated errors are involved in sort of show showing some kindof  a performance bound that is kind of outside of the scope of this course but i think its worthwhile providing some kind of guidance as to where and how we will be ableto achieve that upper bound so the main three ways that we can achieve this kind of upper bound or try to achieve the bestpossible performance out of ample methods the first is the data component"
  },
  {
    "start": "00:17:00.350000",
    "end": "00:17:46.789000",
    "text": "can we provide in some way different data to different of to the various kindof weak predictors that we have here so that we do not cause exactly the same conclusion for each one of them so the second is to somehow randomize their operation sorandomization is the second kind dapproche there and i can actually offer an example of randomization maybe we can actually offer a different set of hyperparameters sorting picked by"
  },
  {
    "start": "00:17:46.789000",
    "end": "00:17:51.799000",
    "text": "some kind of distribution in this architecture see over here in this course u in some other approaches where we have lets say decision trees involved in these predictors again for structure data im referring to then we can randomize their operation by picking different features that they split their sort of trees and there are so many approaches that are"
  },
  {
    "start": "00:17:51.799000",
    "end": "00:17:51.799000",
    "text": "you know i guess too many to quote over here but the third approach is a bit more relevant in this specific rest not architecture is simply use different so the weak learners that we called over here are involved in the rest net architecture and so here we have a predictor of some complexity we have here another predictor larger complexity and yet another predictor or even larger complexity we have effectively implementing"
  },
  {
    "start": "00:17:51.799000",
    "end": "00:19:00.270000",
    "text": "you know the third approach where we have those different week learners each one is offering and then finally the network is deciding based on the composition of those views okay so that has been shown to sortof provide performance advantages and and thatswhat we kind of had this discussion about and sample methods and the third kind  advantage i wanted to quote here for rest n"
  },
  {
    "start": "00:19:00.270000",
    "end": "00:19:38.990000",
    "text": "is there scalabilityso the scalability should be understood from the pointof view of complexity we are effectively able to have three six n or whatever number of residual blocks each one of them will actually be exactly the same as you know any other block over here and therefore we are able to accommodate architectures that are have various various number of these blocks lets saywe see resets with 18 layers 34 layers you know 50 layers 150  102 layers even 150 layers"
  },
  {
    "start": "00:19:38.990000",
    "end": "00:19:38.990000",
    "text": "these are the numbers that we have defined already existing architectures and this is kind of important when you have perception systems that need to comply to some realtime latency requirement evidently the larger the number of layers you have the longer the latencies that you are going to experience taking an image through this kind of pipeline"
  },
  {
    "start": "00:19:38.990000",
    "end": "00:19:48.630000",
    "text": "so if we have lets say a latency of lets say 80 mcene with these kinds of and then we can or so we can 100 are not able to accommodate 102 102 layers where definitely going to be accommodating lets say 50 layers and the exactly the same technology exactly the exact same thinking and behavior of rest nets will be in either of the numbers quoted here in terms of number of layers"
  },
  {
    "start": "00:19:48.630000",
    "end": "00:20:51.870000",
    "text": "so all of these three advantages are coming together to provide a fairly robust architecture has actually proven in the field in both real time and unrealtime applications and able to extract features provide if you like representations onvisual imagery that we have the images that we are feeding into them"
  }
]