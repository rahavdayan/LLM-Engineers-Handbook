[
  {
    "start": "00:00:00.000000",
    "end": "00:00:38.239000",
    "text": "so this is basically what is happening in a an example over here where we have an input image and we are actually sliding  a kernel a 3x3 kernel and we are getting an an aafeature map so the input feature map here is just has one we will be calling sometimes this depth channel and the output feature map has again one channel over here and what we have here is we have"
  },
  {
    "start": "00:00:38.239000",
    "end": "00:00:45.559000",
    "text": "a couple of things that we need to introduce as terms in convolutional operations that our actual doing and inside the convolutionsthe first is the form of the concept of padding and typically we are padding the u input feature maps in order to do two things"
  },
  {
    "start": "00:00:45.559000",
    "end": "00:01:18.640000",
    "text": "we achieving two things probably you have noticed that in an earlier kindof discussion or we had the operation of cross correlation operation in this in this kind of image"
  },
  {
    "start": "00:01:18.640000",
    "end": "00:01:31.079000",
    "text": "over here the output feature map was always smaller in terms de speciaal dimensions compared to the input feature map and it is evidently so because the only way that this output feature k can beexactly the same size as the input is when the kernel is 1 by one so when the kel has a special extent of 1 by one then we have exactly that situation"
  },
  {
    "start": "00:01:31.079000",
    "end": "00:02:07.360000",
    "text": "but in most cases where the can wont be onebyone we will expect this output feature maps to shrink in terms of spatial content and we do not want them to shrink too much because sooner or later we will be running out of spatial dimensions in our outputs and therefore we cannot really go deep to construct deep architectures in these networks so what we expect to makeare have done"
  },
  {
    "start": "00:02:07.360000",
    "end": "00:02:49.959000",
    "text": "is we have with padding we are trying to manage this special extent reduction on one hand as you can see if we had this padding over here then the output feature map is going to be much larger than otherwise so if you can imagine that without a padding then this sort of output feature map would actually be i cant really sortof tell you exactly the dimensions but if you do it visually then you can actually see its going to be probably something like a3x3 output"
  },
  {
    "start": "00:02:49.959000",
    "end": "00:03:31.000000",
    "text": "now the sort of another another advantage of padding is that we allow the kel to actually move into locations which would not be ableto move otherwise so a kernel as we discussed  a bit earlier contains some values and we would like all of the pixels including the edge pixels of the input feature map to be correlated with all of the other pixels of the all of the pixels of the kel and therefore padding allows us to to do so"
  },
  {
    "start": "00:03:31.000000",
    "end": "00:03:37.070000",
    "text": "otherwise you can imagine this red kernel over here will actually be only able to correlate with those three pixels of the input feature map"
  },
  {
    "start": "00:03:37.070000",
    "end": "00:04:24.270000",
    "text": "now this pixel over here can be correlated with both this pixel of the kernel and that pixel of the and this pixel and this pixel of the sort of kel that we have so we have the ability to sortofget more information especially towards the edges of that input feature map with padding another parameter that we should also sort of understand is this kind de stride so stride is the just like the stride that you as you walk it"
  },
  {
    "start": "00:04:24.270000",
    "end": "00:05:05.600000",
    "text": "this here actually refers to the number of pixels that you are skipping over the in order for you to be ableto do the next correlation so here you see two locations of that kernel in that location and the blue location the red location the blue location if your stride was one then the blue k have been right here and while with a stride of two then we dont get one correlation operation for every pixel of the input feature map"
  },
  {
    "start": "00:05:05.600000",
    "end": "00:05:09.240000",
    "text": "and this is obviously is helping us to manage the complexity of these filters to the opposite direction of what we have said earlier in a sense that in some instances we prefer to get for some of the layers of the convolutional neuron the stide parameter to be larger than one typically the strides parameter of height and width are going to be the same so thats what you see over here"
  },
  {
    "start": "00:05:09.240000",
    "end": "00:05:28.440000",
    "text": "bottom line is that all these parameters and far more that are to follow are hyperparameter optimization and we are going to be optimizing them for using hyperparameteroptimization in order for us to define the completearchitecture of of a cnc here you see some animations that kindof reinforce what we have just quoted ed without padding the kel"
  },
  {
    "start": "00:05:28.440000",
    "end": "00:06:26.720000",
    "text": "the output feature map is going to be u potentially significantly reduced in terms of spatial extent something will make any subsequent cor correlation with kels you know not very useful with padding this is because we avoid that and here we actually have padding combinations of padding and stride"
  },
  {
    "start": "00:06:26.720000",
    "end": "00:06:31.840000",
    "text": "so i suggest that you study this kind of animations to just get the gist as to what padding andactually offering to us but now the time has come to look at the operation of the convolutional neuron network and in fact the describe if you like the single convolutional kindof layer in in detail we will start drawing a snapshot of  a cnc layer operation that will actually help us to understand the general case where we have input u and output feature maps coming into the cnc layer"
  },
  {
    "start": "00:06:31.840000",
    "end": "00:06:43.199000",
    "text": "but however these input and output feature maps possess different depths and this is another parameter that we have to understand you knowthat the we are responsible for designing these layers with that that the depth of what we will produce is our responsibility to to design so lets write now draw if you like a  a picture of that cnn layer in operation okay let me call it the the snapshot"
  },
  {
    "start": "00:06:43.199000",
    "end": "00:07:12.520000",
    "text": "we will see just â€” a single snapshot of that layer and this will also help us understand the u what is the convolutional neuron we already have seen the sortofsigmoidal kind of neuroner convolutional neuron in front of us so the snapshot let me call it snapshot of a cnc of  a cncoperation all right so lets draw now the general case as we discussed that we have an input volume this input volume is associated with hthe output feature map of an earlier layer"
  },
  {
    "start": "00:07:12.520000",
    "end": "00:07:15.309000",
    "text": "lets call that layer lminus one this is basically the feature map that was generated by the previous layer in general and well have  mlminus one it will have some kind of width see here this is wl  minus one and the height over here would actually be okay this is a depth and the height over here will actually be h l  minus one all right"
  },
  {
    "start": "00:07:15.309000",
    "end": "00:07:38.639000",
    "text": "so thats basically the dimensions of my incoming volume and this incoming volume has some kind de resolution in terms of number of height and width pixels let me just draw them quickly because we would like to now draw the u what will be the output of out of this operation which is the output feature map now the output is going to be generated atthis specific moment in time i have in general a filter that has 3x3 special extent it is located"
  },
  {
    "start": "00:07:38.639000",
    "end": "00:08:41.800000",
    "text": "lets say here at this moment in time because thats why you call it a snapshot and it has some depth i want to discuss a little bit the depth what makes sense for this depth of the filter to be but it when it is located over here for sure im expecting to have some output feature map this output feature map will be probablysmaller in terms of spal extent thats why im kindof drawing it like this"
  },
  {
    "start": "00:08:41.800000",
    "end": "00:08:46.200000",
    "text": "ofpixels okay and we have some kind of a depth and this depth is definitely something that i need to control because its oneof my main design parameters imill be calling this depth ml and evidently we have  a different hl and wls dimensions and this is basically my you know volumes input and output volumes in general going to have input and output fors so the question i actually have right now is to understand  a little bit about the depth of the filter and we have three options either the depth will actually be"
  },
  {
    "start": "00:08:46.200000",
    "end": "00:08:46.200000",
    "text": "and there are alsodeeper than the input feature map shallower than the inputfeature maps or exactly the same depth as the inputsider map so lets try to do some kind of reasoning over here does it make any sense for the filter to be deeper than a inputpointer map and if you think about it the answer is no it does not really make  a lot of sense because at the end of the day we are goingto be correlating the contents of that filter with the contents of the inputparticipatingto be picking up anything from the input feature map because we are going to so why have it deeper"
  },
  {
    "start": "00:08:46.200000",
    "end": "00:09:36.150000",
    "text": "okay so you know theres no point of doing so if it is shallower than the inputfeature maps also it does not really make a lot of sense because we are goingto leave content that the input features map u contains for us on the table so the so the only reasonable assumption is this filter to be exactly the same in terms of the inputfeature map depth right in terms of this terms of depth of the input fmap so its just basically draw it as such and it in fact"
  },
  {
    "start": "00:09:36.150000",
    "end": "00:09:43.160000",
    "text": "it is really this filter that is going to be the one that we are going to be using to do  this kind of a threedimensional kind of a correlation over here now to understand the contents of that correlation is kindly important and what is actually even more important to understand what it will generate as we will see shortly what it will not generate it will not generate the whole volume over here but it will actually generate only one slice out of thatoutput volume okay to understand that kind of important point"
  },
  {
    "start": "00:09:43.160000",
    "end": "00:09:49.590000",
    "text": "let me take the sortofsofor that specific snapshot that im actually right now im generating thespecific let me draw that like like there somespecific result which is a scaler therefore its a result of  a single pixel from this column which is located at the coordinate i comma j so specially wise"
  },
  {
    "start": "00:09:49.590000",
    "end": "00:09:49.590000",
    "text": "and i hope you remember what we have seen earlier in the sortof example architecture sorry in the cnc architecture diagramwe are let just show you u that kind of diagram again for that specific snapshot lets say the blue la snapshot im actually generating this scalar result and using just one kernel a filter of depth one in this case so as it will actually as it actually turns out that fil that filter at that specific snapshot it will do a threedimensional correlation and it will still generate  a single scaler for me okay and that single scalar will be at  a specific depth okay"
  },
  {
    "start": "00:09:49.590000",
    "end": "00:10:17.150000",
    "text": "and the special coordinates of thatthat the one i just drew now we will call that depth with an index in a moment but what i want to do here is to just draw the complete column of pixels at icommaj location let me just rotate them this column 90Â° and write it over here it will be evidently this dimension will be ml the depth dimension and this is the because we are correspond to the earth layer and let me just do exactly the same thing with the filter so im actually taking the filter and decomposing it over here to the 3x3 kels that itcontains and so these are going to be my3x3kernels"
  },
  {
    "start": "00:10:17.150000",
    "end": "00:10:17.150000",
    "text": "and this will be of dimension mlminus1 so just took the filter rotated 90Â° and just decompos into its kels this is the lminus one layer and so since im going to be generating a scaler lets assume that im generating right now at that specific snap sort the this is the icommaj coordinate this is the column that corresponds to the elayer and the icomputer"
  },
  {
    "start": "00:10:17.150000",
    "end": "00:11:16.480000",
    "text": "and then here this scalar over here this scalar is going to be represented by theletterz and well have evidently i comma j as  a special coordinates and we have"
  },
  {
    "start": "00:11:16.480000",
    "end": "00:11:39.030000",
    "text": "a depth coordinate which i will designate with the letter kl and evidently 1 is less than or equal to kl is less than or equal to mls and this will actually be the values that the kl index which is the depth index can take and i will actually be using also an corresponding index to address each one of those kels which are going to be used forthe the filter"
  },
  {
    "start": "00:11:39.030000",
    "end": "00:12:08.160000",
    "text": "and i am going to also need  to define two other indexes the first index is going to be u and the other index goingto be v and this indices will actually be used to as spatial coordinates of the kernel okay so myequation so"
  },
  {
    "start": "00:12:08.160000",
    "end": "00:12:21.350000",
    "text": "is the following so given i comma j commas kl given in other words the coordinates of the scalar which i want to generate my calar z i comma kl are going to be given by three summenations different correlation operation"
  },
  {
    "start": "00:12:21.350000",
    "end": "00:12:45.269000",
    "text": "the one that we just did in an in a earlier so this is usummation over u and v definitely im expecting the special content of that kind of filter to be correlated and therefore dot product to take the dot product with the contents of the input image okay so this is the two summations over here but also im expecting to now do a threedimensional correlation operation thats  a third summation over an index"
  },
  {
    "start": "00:12:45.269000",
    "end": "00:13:14.360000",
    "text": "ill be calling kl minus1 and this index addresses the specific kernel whichim going to be using so kl minus one is definitely the less than or equal to one and less than or equal to mlminus one ina similar way as we have seen earlier so what is this kind of correlation it will be q of i u j v comma k l1 time w where w now are the contents of the of the kernel that now has u cmccccccckl1 all right so we have in fact the w is not the cond of the kernel line over here that for specifying this line i have the u commav coordinates spal coordinates of the kernel"
  },
  {
    "start": "00:13:14.360000",
    "end": "00:13:29.110000",
    "text": "that specific kernel however is provided by this index is identified by this index so this specific kel is by this index and the scalar it is going to be generating is the located at the kl depth thats why i need this w of q commasv komamaklcommakl minus one okay so this will actually be the weights that are going be so store in those in in those filters"
  },
  {
    "start": "00:13:29.110000",
    "end": "00:14:09.240000",
    "text": "and in fact we only have one filter right now so a fourdimensional tensor to identify the parameters that we have used in this specific dot product over here this is  a threedimensional dot product and as you can imagine as im sliding the filter to another location in the next snapshot the only thing actually is changing is the space coordinate that is being produced in this scaler so the only thing so by moving the filter around im changing the i comma j of what im producingtherefore what im actually going to be producing is a slice"
  },
  {
    "start": "00:14:09.240000",
    "end": "00:00:-1.000000",
    "text": "a specific slice out of this sort of output feature map so the specific slice im just drawing over here just one of the ml slices so that ml slices generates the complete volume so this slice is the one that i am going to be generating this complete slice so effectively  a matrix and so from one filterill be generating  single matrix and therefore and this is the important conclusion from we need multiple"
  },
  {
    "start": "00:00:-1.000000",
    "end": "00:14:09.240000",
    "text": "we need multipleoutput feature mapvolume so for 12 we need multipleto be creating multiple fatures in fact this thing over here is really the connectivity diagram of the convolutional neuron what we call a convolutional a single filter is and the operation actually we see over here is the operation of the convolutional neuron and this is all of these parameters that we have used over here"
  },
  {
    "start": "00:14:09.240000",
    "end": "00:15:54.069000",
    "text": "the contents if you like the filter are the socalled trainable parametersand we will now see an animation of of this thing in in our core site so if i go to my core site and actually scroll down you can see now the threedimensional so first of all before we see the animation we can actually see its exactly the diagram i just drew a bit a different"
  },
  {
    "start": "00:15:54.069000",
    "end": "00:16:41.720000",
    "text": "i have an input volume which is the blue over here with has  a depth d in definitely as we mentioned the input sorry the filter that were going to be using has the same depth din as the input volume doesnt make sense otherwise and then in terms of the output volume if you are going to be generating one slice out of the dout slices so on onethis specific matrix over here where my mouse pointer is"
  },
  {
    "start": "00:16:41.720000",
    "end": "00:16:47.800000",
    "text": "that is going to be what is going to be produced by a single filter and this dotted line here indicates that if you wantto generate the complete output volume with  depth dout you need  out of these filters you need  out of these orange cubes in order for you to be able to generate spy time in this animation in this animation so i think its worth spending some time in this animation"
  },
  {
    "start": "00:16:47.800000",
    "end": "00:00:-1.000000",
    "text": "in this animated it can actually see exactly what i just discussedin this example i have an input feature map of depth three and i have a output feature map of depth two lets assume that that is the sort of  a design parameter which i want to implement therefore if you have an output feat map of two i need two filters and these are the two filters this is the filter w0 and this is the filter w1"
  },
  {
    "start": "00:00:-1.000000",
    "end": "00:16:47.800000",
    "text": "and evidently the each each of these filters has of dep depth three because three is also the depth of the input feature map snapshot that i just drew on piece of paper this filter is located at this specific location in my input feature map and it is responsible for creating this scalar z which is nine in this case okay"
  },
  {
    "start": "00:16:47.800000",
    "end": "00:18:39.750000",
    "text": "so if you may and as far as the output feature map is concerned this filter is only able to plot if you like to determine the this specific slice of the output feature map if i want to continue then we will see that the second filter is the one which is involved in the creation of ofeature this is really the essence of a threedimensional convolution"
  },
  {
    "start": "00:18:39.750000",
    "end": "00:19:08.270000",
    "text": "i suggest that you spend some time on this animation trying to understand what is going on and you can toggle the movement just to be able simply to replicate the output scaler from the input values which have been provided overhere  a bit on this presentation of the snapshot operation of â€” a layer the site over here has is squatting some kind of important formulas regarding the size the special dimensions of the output feature map"
  },
  {
    "start": "00:19:08.270000",
    "end": "00:19:21.640000",
    "text": "i think itsimportant to note them down and so it is the floor of the height of the input feure map plus two the padding size minus the kernel size divided by the strides and plus one okay so this is the formula that will that you can actually use to understand exactly what will be your output feature maps are in terms of spatial dimensions and of course this will be the input featuremap sizes for the for the layer that follows"
  },
  {
    "start": "00:19:21.640000",
    "end": "00:19:25.710000",
    "text": "okay so what will actually be those layers i think its you know its quite important to get into the udiscussion now about other architectural features before we go into some kind of a discussion about the advantages of convolution layers as compared to fully connected layers which i think is best demonstrated using an example before we go into that example lets look at another operation that well be calling the max pulling layer or in general pulling layer which is actually described here and its best demonstrated with this kindof image and this case what we see"
  },
  {
    "start": "00:19:25.710000",
    "end": "00:20:15.080000",
    "text": "we have an input feature map that has depth of one in this case and we do still have the concept of if you like of a kernel that we slide around just like in the convolutional layer but in this case insteadof  a nonlinear function like reu that we have actually also seen in the fully connected layers that we are still going to see in the evolutional layer as we will see in that example"
  },
  {
    "start": "00:20:15.080000",
    "end": "00:20:39.789000",
    "text": "we will have another function lets call that function in this specific case its shown as the max function wherethe idea behind this is that i am still going to see in our own in this particular instancegoing to not form a correlation result over here like  a dot product but were going to select the maximum element of what we see in the input feature map typically we apply the that function at for each of the channels of the input feature map but in some instances we may apply it also across the depth dimension"
  },
  {
    "start": "00:20:39.789000",
    "end": "00:21:31.669000",
    "text": "what we are achieving is evidently we are achieving some reduction in the spatial dimensions of the output feature maps and that kind of intuitively understood as trying to select the mostimportant features of the input feature map and transfer out into the layer above for further process"
  },
  {
    "start": "00:21:31.669000",
    "end": "00:00:-1.000000",
    "text": "say okay so that is the max pooling layer in this case which is typically interl with convolutional layers as we will see in some example architectures closing i want to emphasize the another u kind of specific parameterization of the convolutional layer we call here the one by one convolutional layer and it is definitely a sortofa layer that it is being met in various kind of architect lectures and maybe it doesnot really make a lot of sense to you"
  },
  {
    "start": "00:00:-1.000000",
    "end": "00:21:31.669000",
    "text": "the moment you see this kindof animation over here why in earth were going to do one by one convolutions since we as we discussed were trying and typically the kernel sizes have larger dimensions than one by one but i think the the explanation potentially could be more intuitively understood if we see the threedimensional version of that one by one convolution so we have  a see here the orange u filter that evidently the k size is one by oneand we have"
  },
  {
    "start": "00:21:31.669000",
    "end": "00:23:18.710000",
    "text": "as we discussed earlier depth d that matches the depth of the input feature map and as we also discussed earlier the this filter operation will move around we were sliding around this filter and were creating one slice for this filter so in this one by one convolution we have just one slice"
  },
  {
    "start": "00:23:18.710000",
    "end": "00:23:18.710000",
    "text": "and as you can see what we are achieving here we are forming a scalar by combining the depth compressing the whole depth dimension so we actually have we are seeing typically this type of layers lets say towards theend of an network the top of the network where we just before the head where we want to just summarize everything we have done and then we just need  to compress that information to a matrix and potentially that kindof slice is going to be flattened in order for being passed over into the head which may consist of fully connected layers as well"
  },
  {
    "start": "00:23:18.710000",
    "end": "00:23:40.240000",
    "text": "see that in â€” okay so thats one application ofthe onebyone convol convolution operation all right so it it it kind of looks like an multilayer petron or a dense layer as it is combining these depth dimensions into that scaler all right so lets now see some example architectures these example architectures could potentially be like the toy network that we see here where we have"
  },
  {
    "start": "00:23:40.240000",
    "end": "00:23:42.549000",
    "text": "as we discussed the convolutional layer followed by nonlinearity and max pulling layers and finally at the end we expect to see  a fully connected layer thatto play the role of the of the head of the network where we have lets say in this case five classes that we would like to do a classification on but instead of looking at this toy network work and i think its  a bit more instructive to look at i will call it canonical architecture called vgg from the initials of the authors of that kind of architecture this architecture is"
  },
  {
    "start": "00:23:42.549000",
    "end": "00:23:49.230000",
    "text": "i call an architecture that i suggest students to start from every time they want to look at these convolutional networks because theydo represent some kind of a initial good architecture that we can sortofmake some conclusions in regarding the dimensionality and the patterns that we expect to see in  a typical cnc architecture instead instead looking if you like in the most modern versions of cnn i think its worthwhile looking at this to understand  a couple of things so the first thing that wed like to capture over here is this image and understand what is really happening"
  },
  {
    "start": "00:23:49.230000",
    "end": "00:24:15.520000",
    "text": "okay so the image is the in this figure we seeso a cnn network that consist of multiple layers and one striking thing from the getgo that you can see is that the cnn is the dimensionality of the cnn is in terms of spatial dimensions"
  },
  {
    "start": "00:24:15.520000",
    "end": "00:00:-1.000000",
    "text": "is evidently shrinking as we are going deeper so we see the convolutional layers followed by max pulling layers u for and then towards the end we see the fully connected network which is the head"
  },
  {
    "start": "00:00:-1.000000",
    "end": "00:24:15.520000",
    "text": "so in terms of spatial dimensions we are actually decreasing the spatial dimensions because evidently we are using kels which are larger than usone by one and and but on at the same time what we are also seeing is"
  },
  {
    "start": "00:24:15.520000",
    "end": "00:25:53.480000",
    "text": "we see an increase in the depth dimension so in terms of numbers over here 224x224 pixels are the spatial dimensions of the input images and then and then we have a 64 to be the depth dimension of the or equivalent the number of neurons in the u that we have in or the number of filters that we have in that layer so this is also our responsibility so our responsibility are twofold"
  },
  {
    "start": "00:25:53.480000",
    "end": "00:00:-1.000000",
    "text": "one is to with  a padding and stride parameters for massage these kindof special dimensions we need and at the same time also select the number of filters how many convolutional neurons are we going to engage in that layer so as you can see we go from 64 128 256 512 that is really the end game with respect to numberoffilters"
  },
  {
    "start": "00:00:-1.000000",
    "end": "00:25:53.480000",
    "text": "the intuition behind the increase in the number of filters as the network becomes deeper and deeper is the following the network is learning more and more complicated features as we are going deeper the first layers are the are are learning representationswhich are simple shapes i will call it similar things that you would expect to for you to understand when"
  },
  {
    "start": "00:25:53.480000",
    "end": "00:27:40.789000",
    "text": "you look at if you like at a kind of  primitive shape like  a circle a triangle or whatever have you and the subsequent kind of layers are actually learning more and more complicated representations"
  },
  {
    "start": "00:27:40.789000",
    "end": "00:28:06.830000",
    "text": "well see in  a moment some examples of exactly what these layers are learning and by suitable visualizations so as you are trying to create combinations of these simpler representations you probablyneed all to be doing more of those combinations as you go deeper because you are trying  because you are trying to understand whether or not theres one combination that actually magically generating the right set of representations in subsequent deeper layers such that your head can actually do the job"
  },
  {
    "start": "00:28:06.830000",
    "end": "00:28:06.830000",
    "text": "so thats the first intuition regarding the increase in the depth of the of the of the filters the second is that you can afford to i mean you can afford having that kindof increase in the depth of the filter and without really paying too muchcomplexity performance sorry complexity in the terms of number of operations because your special dimensions of the feature maps which are produced from a earlier operations are shrinking so you increase the number of filter parameters and still youre not really paying any any complexity this sortof penalty because"
  },
  {
    "start": "00:28:06.830000",
    "end": "00:28:39.480000",
    "text": "okay so these are the two things that we need we can actually mention about this kind of architecture that looks again like spherical but this pyramid is essentially a kind of works in â€” â€“ a different way as as ascomparing to what we have seen in fully connected architect pictures and now i think its worthwhile spending some time on uon on an example and this example is a python notebook this example is actually shown over here you can actually click on this and open it in pap for execution however the notebook in your case over here will actually be working as it is"
  },
  {
    "start": "00:28:39.480000",
    "end": "00:29:44.549000",
    "text": "so in the next video well go through this example and then see exactly whats going on in terms of and the api and the implementation of acn"
  }
]