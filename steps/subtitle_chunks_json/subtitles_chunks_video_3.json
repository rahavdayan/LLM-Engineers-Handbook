[
  {
    "start": "00:00:03.280000",
    "end": "00:00:16.029000",
    "text": "so this is basically what is happening in a an example over here where we have an input image and we are actually sliding a kernel a 3x3 kernel and we are getting an an aafeature map"
  },
  {
    "start": "00:00:22.349000",
    "end": "00:00:38.229000",
    "text": "so the input feature map here is just has one we will be calling sometimes this depth channel and the output feature maps has again one channel over here and what we have here is we have"
  },
  {
    "start": "00:00:39.630000",
    "end": "00:00:47.869000",
    "text": "a couple of things that we need to introduce as terms in convolutional operations that our actual doing and inside the convolutionalism nt we actually doing and inside the convolutional new networks so the first is the form of the concept of padding"
  },
  {
    "start": "00:00:55.910000",
    "end": "00:01:05.030000",
    "text": "and typically we are padding the u input feature maps in order to do two things we achieving two things"
  },
  {
    "start": "00:01:09.270000",
    "end": "00:01:16.030000",
    "text": "perhaps you have noticed that in an earlier kindof discussion or we had the operation of cross correlation operation in this in this kind of image over here"
  },
  {
    "start": "00:01:22.429000",
    "end": "00:01:28.030000",
    "text": "the output feature map was always smaller in terms de speciaal dimensions compared to the input feature map and it is evidently sred to the input feature map and it is evidently so because"
  },
  {
    "start": "00:01:31.069000",
    "end": "00:01:49.789000",
    "text": "the only way that this output feature mk can be exactly the same size as the input is when the kernel is 1 by one so when the kel has a special extent of 1 by one then we have exactly that situation"
  },
  {
    "start": "00:01:51.630000",
    "end": "00:01:51.630000",
    "text": "but in most cases where the can wont be onebyone we will expect this output feature maps to shrink in terms of spatial content"
  },
  {
    "start": "00:01:54.190000",
    "end": "00:02:07.350000",
    "text": "and we do not want them to shrink too much because sooner or later we will be running out of space dimensions in our owill be running out of spatial dimensions in our outputs and therefore we cannot really go deep to construct deep architectures in these networks"
  },
  {
    "start": "00:02:14.110000",
    "end": "00:02:20.030000",
    "text": "so what we expect to do is we have with padding we are trying to manage this special extent reduction on one hand as you can see"
  },
  {
    "start": "00:02:23.509000",
    "end": "00:02:31.509000",
    "text": "if we had this padding over here then the output feature map is going to be much larger than otherwise"
  },
  {
    "start": "00:02:33.630000",
    "end": "00:02:41.390000",
    "text": "so if you can imagine that without a padding then this sortof output feature map would actually be i cant realoutput feature map would actually be"
  },
  {
    "start": "00:02:43.509000",
    "end": "00:02:48.350000",
    "text": "i cant really sort of tell you exactly the dimensions but if you do the if you see the sort of if you do it visually then you can actually see its going to be probably something like a 3x3 output"
  },
  {
    "start": "00:02:59.550000",
    "end": "00:03:30.990000",
    "text": "now the sort of another advantage of padding is that we allow the kel to actually move into locations which would not be able to move otherwise so a kernel as we discussed a bit earlier contains some values and we would like all of the pixels including the edge pixeuld like all of the pixels including the edge pixels of the input feature map to be able to be correlated with all of the other pixels of the allofthepixels of the kel and therefore padding allows us to do so"
  },
  {
    "start": "00:03:34.630000",
    "end": "00:03:48.589000",
    "text": "otherwise you can imagine this red kernel over here will actually be only be able to correlate with those three pixels of the input feature map"
  },
  {
    "start": "00:03:51.670000",
    "end": "00:04:11.910000",
    "text": "now this pixel over here can be correlated with both this pixel of the kernel and that pixel of the and this pixel and this pixel of theof the and this pixel and this pixel of the sort of kel that we have so we have the ability to sortofget more information especially towards the edges of that input feature map with padding"
  },
  {
    "start": "00:04:14.949000",
    "end": "00:04:24.270000",
    "text": "another parameter that we should also sort of understand is this kind de stride so stride is the just like the stride that you as you walk it"
  },
  {
    "start": "00:04:27.870000",
    "end": "00:04:33.830000",
    "text": "this here actually refers to the number of pixels that you are skipping over the in order for you to be ableto do the next correlation"
  },
  {
    "start": "00:04:39.310000",
    "end": "00:04:46.870000",
    "text": "so here you see two locations onelation so here you see two locations of that kernel in that location and the blue location the red location the blue location"
  },
  {
    "start": "00:04:54.430000",
    "end": "00:04:54.430000",
    "text": "if your stride was one then the blue k have been right here"
  },
  {
    "start": "00:04:57.990000",
    "end": "00:05:09.230000",
    "text": "and while with a stride of two then we dont get one correlation operation for every pixel of the input feature map and this is obviously is helping us to manage the complexity of these filters"
  },
  {
    "start": "00:05:11.909000",
    "end": "00:05:23.070000",
    "text": "in fact goes slightly to the opposite direction of what we have said earlier insense that in some instances we prefer to get for some of the layers of the convolutional neuron"
  },
  {
    "start": "00:05:28.430000",
    "end": "00:05:36.629000",
    "text": "the the stride parameter a larger than one typically the stride parameter of height and width are going to be the same so thats what you see over here"
  },
  {
    "start": "00:05:40.670000",
    "end": "00:05:40.670000",
    "text": "bottom line is that all these parameters and far more that are to follow are hyperparameter optimization"
  },
  {
    "start": "00:05:51.830000",
    "end": "00:05:51.830000",
    "text": "in order for us to define the complete architecture of of  a cnn here you see somelete architecture of of a cnn"
  },
  {
    "start": "00:05:56.790000",
    "end": "00:06:03.189000",
    "text": "here you see some animations that kindof reinforce what we have just quoted ed without padding the kel"
  },
  {
    "start": "00:06:05.550000",
    "end": "00:06:17.070000",
    "text": "the output feature map is going to be u potentially significantly reduced in terms of spatial extent something will make any subsequent cor correlation with kels you know not very useful with padding"
  },
  {
    "start": "00:06:24.589000",
    "end": "00:06:26.710000",
    "text": "this is because we avoid that and here we actually have padding combinations of padding and stride"
  },
  {
    "start": "00:06:29.790000",
    "end": "00:06:33.830000",
    "text": "so i suggest that you study this kind of animations to just get the gist as to whatind of animations to just get the gist as to what padding and stride are actually offering to us"
  },
  {
    "start": "00:06:37.150000",
    "end": "00:06:43.189000",
    "text": "but now the time has come to look at the operation of the convolutional neuron network and in fact the describe"
  },
  {
    "start": "00:06:49.070000",
    "end": "00:07:09.390000",
    "text": "if you like the single convolutional kindof layer in in detail we will start drawing a snapshot of a cnn layer operation that will actually help us to understand the general case where we have input u and output feature maps coming into the cnn layer but however these input and output feature maps posut however"
  },
  {
    "start": "00:07:12.510000",
    "end": "00:07:15.309000",
    "text": "these input and output feature maps possess different depths and this is another parameter that we have to understand"
  },
  {
    "start": "00:07:19.589000",
    "end": "00:07:28.749000",
    "text": "you know that the we are responsible for designing these layers with that that the depth of what we will produce is our responsibility to to design so lets write now draw"
  },
  {
    "start": "00:07:31.710000",
    "end": "00:07:38.629000",
    "text": "if you like a  picture of that cnn layer in operation okay let me call it the the snapshot"
  },
  {
    "start": "00:07:40.670000",
    "end": "00:07:47.710000",
    "text": "we will see just a single snapshot of that layer and this will also help us understand the uo help us understand the u what is the convolutional neuron"
  },
  {
    "start": "00:07:49.350000",
    "end": "00:07:59.950000",
    "text": "we already have seen the sort of sigmoidal kind of neuroner now well see in the fully connected dense layer architectures now well see the convolutional neuroin frontoftheworld"
  },
  {
    "start": "00:08:03.909000",
    "end": "00:08:05.430000",
    "text": "so the snapshot let me call it snapshot of a cnn of a cnnoperation all right so lets draw now the general case as we discussed that we have an input volume this input volume is associated with h"
  },
  {
    "start": "00:08:41.790000",
    "end": "00:08:41.790000",
    "text": "the output feature map of an earlier layer"
  },
  {
    "start": "00:09:32.670000",
    "end": "00:09:32.670000",
    "text": "letd be called that layer l minusof an earlier layer lets call that layer l  l  l  l  l  l  l  l  l  l  l  l  l  l  l  l  l  l  l  l  l  l  l  l  l  l  l  l  l  l  l  l  l  l coming volume and this incoming volume has some kind of resolution"
  },
  {
    "start": "00:09:40.269000",
    "end": "00:09:49.590000",
    "text": "in terms number of height and width pixels let me just draw them quickly because we would like to now draw the u what will be the output of out of this operation which is the output feature map"
  },
  {
    "start": "00:09:56.750000",
    "end": "00:10:08.310000",
    "text": "now the output is going to be generated at this specific moment in time i have in general a filter that has 3x3 special extent it is located"
  },
  {
    "start": "00:10:09.910000",
    "end": "00:10:17.150000",
    "text": "lets say here at this moment in time because thats why you call it a snapshot and its you call it a snapshot and it has some depth i want to discuss a little bit the depth"
  },
  {
    "start": "00:10:18.790000",
    "end": "00:10:27.069000",
    "text": "what makes sense for this depth of the filter to be but it when it is located over here for sure im expecting to have some output feature map"
  },
  {
    "start": "00:10:31.269000",
    "end": "00:10:52.600000",
    "text": "this output feature map will be probablysmaller in terms of spal extent thats why ime kindof drawing it like this it has some kind or a number ofpixels okay and we have some kind of at"
  },
  {
    "start": "00:10:59.550000",
    "end": "00:11:19.310000",
    "text": "i need to control because its one of my main design parameters ill be calling this depth ml and evidently we have a different hl dimensions and this is basically my"
  },
  {
    "start": "00:11:21.550000",
    "end": "00:11:23.069000",
    "text": "you know volumes input and output volumes in general going to have input and output fors"
  },
  {
    "start": "00:11:29.350000",
    "end": "00:11:32.110000",
    "text": "so the question i actually have right now is to understand a little bit about the depth of the filter and we have three options"
  },
  {
    "start": "00:11:39.030000",
    "end": "00:11:57.310000",
    "text": "or the depth of the filter will actually be deeper than the input feature map shallower than the inputandort feature map shallower than the inputfeature maps or exactly the same depth as the inputfeatured map"
  },
  {
    "start": "00:11:59.750000",
    "end": "00:12:01.750000",
    "text": "so lets try to do some kind of reasoning over here does it make any sense for the filter to be deeper than the inputfeature map and if you think about it the answer is no"
  },
  {
    "start": "00:12:03.949000",
    "end": "00:12:16.670000",
    "text": "it does not really make a lot of sense because at the end of the day we are goingto be correlating the contents of that filter with the contents of this outputfeature map and if the filter is actually deeper then our the in  but when the filtr is actually deep then i am not going to be pr is actually deeper"
  },
  {
    "start": "00:12:18.949000",
    "end": "00:12:28.350000",
    "text": "then we are not going to be picking up anything from the input feature map because we are going to so why have it deeper"
  },
  {
    "start": "00:23:18.710000",
    "end": "00:23:18.710000",
    "text": "okay so you know theres no point of doing so if it is shallower than the inputfeature maps"
  },
  {
    "start": "00:24:43.310000",
    "end": "00:24:43.310000",
    "text": "also it does not really make a lot of sense because we are goingto leave content that the input features map u contains for us on the table so the so the only reasonable assumption is this filter to be exactly the same in terms of the inputfeatured  deeper"
  },
  {
    "start": "00:24:57.870000",
    "end": "00:24:57.870000",
    "text": "so the onems of the input feature map depth right in terms of this terms of depth of the input f map so its just basically draw it as a such and it in fact is really this filter that is going to be the one that we are going to be using to do this kindof a threedimensional kind of a correlation over here now to understand the contents of that correlation is kind of important and what is actually even more important to understand what it will generate as we will see shortly what it will not genneona as we will see shortly what it will not generate"
  },
  {
    "start": "00:31:58.389000",
    "end": "00:32:04.149000",
    "text": "it will not generate the whole volume over here but it will actually generate only one slice out of that output volume okay to understand that kindof important point lets do the following"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "let me take the sort so for that specific snapshot that im actually right now im generating thespecific let me draw that like there somespecific result which is scaler"
  },
  {
    "start": "00:34:10.310000",
    "end": "00:34:10.310000",
    "text": "therefore itse a result of — –pixel from this column which is located at the coordinate i comma j so specially wise and i hope you remember what we have seen earlier in the sort of example architecture"
  },
  {
    "start": "00:38:10.670000",
    "end": "00:38:10.670000",
    "text": "sorry in the cnn architecture diagram we are let just show you u that kindof diagram again for that specific snapshot lets say the blue la snapshot"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "im actually generating this scalar result and using just one kernel"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "so as it will basically as it actually turns out that fil that filter at that specificyu turns out that fil that filter at that specific snapshot"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "it will do a threedimensional correlation and it will still generate a single scaler for me okay and that single scalar will be at — – a specific depth okay"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "and the special coordinates of that scalar is i comma j that the one i just drew now we will call that depth with an index in a moment"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "but what i want to do here is to just draw the complete column of pixels at i caj location let us just rotate them this column 90° and write it over here it wil"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "they this column 90° and write it over here it will be evidently this dimension will be ml the depth dimension and this is the because we are correspond to the earth layer"
  },
  {
    "start": "00:38:13.349000",
    "end": "00:38:13.349000",
    "text": "and let me just do exactly the same thing with the filter so im actually taking the filter and decompose it over here to the 3x3 kels that it contains"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "and so these are going to be my3x3kernels and this will be of dimension mlminus1"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "so just took the filter rotated 90 degrees and just decompot into its kels this is the l minus one layer and soin its kels this is the l minus one layer and so since im going to be generating a scaler let’simply that ime generating right now at that specific snap sort"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "the this is the icomma j coordinate this is the column that corresponds to the elayer and the icommas j coordinate let simply that immam j coordinate"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "over here this calar is going to be represented by the letterz and well have evidently"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "i commatoj as  we will designate with the depthdepth coordinate which i will designate with the letter kl and evidently 1 is less than or equal to kl it is less than or equal to ml"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "and this will actually be the values that the kl index which is the depth index can take and i will actually be using also a corresponding index to address each one of those kels which are going to be used for the determining that kind of scalar z"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "so that scalar z is going to be produced by using allofthefilmr and i am going to also need to define to define two other indexes the first index is going to be u and the other index goingto become v"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "and this indices will actually be used to as spatial coordinates of the kernel"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "okay so myequation so is the following so given i comma j commas kl given in other words the coordinates of the scalar which i want to generate"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "my calar zi commoda kl are going to be given by three summenations seeming already in the plain twodimensional correlation operation"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "the one that we just did in an earlier so this is u summation over u and v definitely"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "ime expecting the special content of that kind of filter to be correlated and therefore dot product to take the dot product with the contents of the input image"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "okay so this is the two summations over here but also is expecting to now do a threedimensional correlation operation"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "thats — a third summe over an indexover an index ill be calling klminus1 and this index addresses the specific kernel which im going to be using"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "so klminus one is definitely the less than or equal to one and less than or equal to mm1 time w where w now are the contents of the of the kernel that now has ucommas vcommas kklminus1 all right"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "so we have in fact the w is not the cond of the kernel ht so we have in fact the w is not the cond of the kernel the cond of the kernel yes we can call them w"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "but w i would associate w with this line over here that for specifying this line i have the u comma v coordinates spal coordinates of the kernel that specific kernel however is provided by this index"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "so this specific kel is by this index and the scalar it is going to be generating is the located at the kl depth thats why this w of qc ca — –   that specific ke  a  "
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "this w of q comma v commas kl comma kl minus one okay so this will actually be the weights that are going be"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "so a fourdimensional tensor is being used here for specifying those parameters that that we are store in those in in those filters and in fact we only have one filter right now so so "
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "commma w product over here this is essentially threedid to another locatio agine as im sliding the filter to another location in the next snapshot"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "the only thing actually is changing is the space coordinate that is being produced in this scaler so the only thing so by moving the filter around im changing the i commas j of what im producing"
  },
  {
    "start": "00:38:40.390000",
    "end": "00:38:40.390000",
    "text": "therefore what im actually going to be producing is a slice a specific slice out of this sort of output feature map so the specific slice im just drawing over here just one of the ml slices generates the complete volume and my own"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "as ire sliding it into another location in the next snapshot we are also doingo ml slices generate the complete volume so this slice is the one that i am going to be generating"
  },
  {
    "start": "00:39:05.510000",
    "end": "00:39:05.510000",
    "text": "this complete slice so effectively a matrix and so from one filter ill be generating a single matrix and therefore and this is the important conclusion from we need multiple"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "we need multipleoutput feature mapvolume so for  a volume for the whole thing for the output feature map we need to be creating multiple fatures"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "in fact this thing over here is really the connectivity diagram of the convolutional neuron wconnectivity diagram of the convolutional neuron"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "what we call a convolutional a single filter is and the operation actually we see over here is the operation of the convolutional neuron and this is all of these parameters that we have used over here"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "the contents if you like the filter are the socalled trainable parametersand we will now see an animation of of this thing in in our core site"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "so if i go to my core site and actually scroll down a little bit then you can see now the threedimensional so first on"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "you can see now the threedimensional so first of all before we see the animation we can actually see its exactly the diagram i just drew a bit a different"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "i have an input volume which is the blue over here with has  has  depth d in definitely as we mentioned"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "the input sorry the filter that were going to be using has the same depth d in as the input volume doesnt make sense otherwise and then in terms of the output volumerating one slice out of the dout slices"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "so on one slice lets say this specific matrix over here where my mouse pointer is"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "that is going to be what is going to be produced by a single filter and this dotted line here indicates that if you wantto generate the complete output volume with depth dout you need dout of these filters"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "you need dout of these orange cubes in order for you to be able to generate one parts worth spending some time in this animation"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "in this animation you can actually see exactly what i just discussed here in this example i have an input feature map of depth three and i have a output feature map of depth two"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "lets assume that that is the sort of a design parameter which i want to implement therefore if i have an output feat map of two i need two filters and these are the two filters"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "this is the filter w0 and this is the filter w1 and evidently the each each of these filters has of dep ddently the each of these filters has of dep depth three because three is also the depth of the input feature map"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "and at every specific snapshot lets assume this is the snapshot that i just drew on pieceof paper"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "this filter is located at this specific location in my input feature map and it is responsible for creating this scalar z which is nine in this case okay"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "so if i may and as far as the output feature map is concerned this filter is only able to plot if you like to determine the this speable to plot"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "if you like or determine the this specific slice of the output feature map if i want to continue then we will see that the second filter is the one which is involved in the creation of of the second slice of the output feature"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "this is really the essence of a threedimensional convolution"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "i suggest that you spend some time on this animation trying to understand what is going on and you can toggle the movement just to be ableto replicate the output scaler from the input values which havethe output scaler from the input values which have been provided overhere a bit on this presentation of the snapshot operation of a layer that the site over here has is squatting some kind of important formulas regarding the size the special dimensions of the output feature map"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "i think itstilly to note them down and so it is the floor of the height of the input feure map plus two  the padding size minus the kernel size divided by the strides and plus one"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "okay so this is the formula that will that you can actually use to understand exactly what will be your output feature maps are in terms of spatial dimensions"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "and of course this will be the inputfeature map sizes for the for the layer that follows okay so what will actually be those layers"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "i think its you know its quite important to get into the u discussion now about other architectural features before we go into some kind a discussion about the advantages of convolution layers as compared to fully co"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "ages of convolution layers as compared to fully connected layers which i think is best demonstrated using an example"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "before we go into that example lets look at another operation that well be calling the max pulling layer or in general pulling layer which is actually described here and its best demonstrated with this kindof image and this this case"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "what we see we have an input feature map that has a depth of one in this case and we do still have the concept of if you like of a kernel that we slide arounept of"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "if you like of a kernel that we slide around just like in the convolutional layer but in this case instead of a nonlinear function like reu that we have actually also seen in the fully connected layers that we are still going to see in the evolutional layer as we will see in that example"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "we will have another function lets call that function in this specific case its shown as the max function"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "wherethe idea behind this is that we are going to not form ot form a correlation result over here like a dot product but were going to select the maximum element of what we see in the input feature map"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "typically we apply the that function at for each of the channels of the input feature map but in some instances we may apply it also across the depth dimension what we are achieving is evidently"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "we are achieving some reduction in the spatial dimensions of the output feature map and that kind of intuitively understood as trying to select the most important featureood as trying to select the most important features of the input feature map and transfer out into the layer above for further process say okay"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "so that is the max pooling layer in this case which is typically interl with convolutional layers as we will see in some example architectures closing"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "i want emphasized the another u kind of specific parameterization of the convolutional layer"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "we call here the one by one convolutional layer and it is definitely a sortofa layer that it is being met in various ksort of a layer that it is being met in various kind architect lectures"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "and and maybe it does not really make a lot of sense to you the moment you see this kindof animation over here why"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "in earth were going to do one by one convolutions since we as we discussed were trying to detect features and typically the kernel sizes have larger dimensions than one by one but i think the the explanation potentially could be more intuitively understood if we see the threedimensional version of this one or twohe threedimensional version of this one by one convolution so we have a see here the orange u filter"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "that evidently the k size is one by one"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "and we have as we discussed earlier depth d that matches the depth of the input feature map and as we also discussed earlier the the this filter operation will move around"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "were sliding around this filter and were creating one slice for this filter so in this one by one convolution we have just one slice and as you can see what we are achieving hereas you can see what we are achieving here we are forming an scalar by combining the depth compressing the whole depth dimension"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "so we actually have we are seeing typically this type of layers"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "lets say towards the end of an network the top of the network where we just before the head where we want to just summarize everything we have done and we have learned in terms of u convolutions operations and across all depth dimensions that we have decided to do and then we just need to compress that information"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "tothen we just need to compress that information to a matrix and potentially that kind of slice is going to be flattened in order for being passed over into the head which may consist of fully connected layers"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "as well see that in okay so thats one application of the onebyone convol convolution operation all right so it it"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "it kind of looks like an multilayer petron or  a dense layer as it is combining these depth dimensionen into that scaler all right"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "so lets now see some example architectures this eo lets now see some example architectures"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "these example architectures could potentially be like the toy network that we see here where we have as we discussed the convolutional layer followed by nonlinearity and max pulling layers"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "and finally at the end of this year we expect to see a fully connected layer that is going to play the role of the of the head of the network where we have"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "lets say in this case five classes that we would like to do a classification on but instead of looking at theset instead of looking at this toy network work"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "and i think its a bit more instructive to look at i will call it canonical architecture called vgg from the initials of the authors of that kind of architecture"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "this architecture is i call an architecture that i suggest students to start from every time they want to look at these convolutional networks because they do represent some kindof good architecture that we can sort of make some conclusions in regarding the dimensionality and the patterns tharegardless the dimensionality and the patterns that we expect to see in a typical cnn architecture"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "instead of looking if you like in the most modern versions of cnn i think its worthwhile looking at this to understand a couple of things"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "so the first thing that wed like to capture over here is this image and understand what is really happening okay so the image is the in this figure"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "we see  a cnn layer so – a cnn network that consist of multiple layers and one striking thing from the getgo that you can see istriking thing from the getgo that you can see is that the cnn is"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "the dimensionality of the cnn is in terms of spatial dimensions is evidently shrinking as we are going deeper so we see the convolutional layers followed by max pulling layers u for and then towards the end we see the fully connected network which is the head"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "so in terms of spatial dimensions we are actually decreasing the spatial dimensions because obviously we are using kelses which are larger than one by one and and but on at the same timeer one by one and and but on"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "at the same time what we are also seeing is we see an increase in the depth dimension so in terms of numbers over here 224x224 pixels are the spatial dimensions of the input images and then and then we have a 64 to be the depth dimension of the or equivalent the number of neurons in the u that we have in or the number of filters that we have in that layer"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "so this is also our responsibility so our responsibility are twofold one is to with  a padding and stride parametwofold"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "one is to with a padding and stride parameters to massage these kind of special dimensions we need and at the same time also select the number of filters"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "how many convolutional neurons are we going to engage in that layer so as you can see we go from 64 128256512 that is really the end game"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "with respect to number of filters the intuition behind the increase in the number of filters as the network becomes becomes deeper and deeper is the following"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "the network is learning more and more complicateg the network is learning more and more complicated features as we are going deeper the first layers are"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "the are are learning representations which are simple shapes i will call it similar things that you would expect to for you to understand when you look at"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "if you like at a kind of  a primitive shape like a circle well see in — or whatever have you and the subsequent kind "
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "moment some examples of exactly what these layers are learning and by suitable visualizations"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "so as you are trying to create combinations of these simpler representations you probably need all to be doing more of those combinations as you go deeper because you are trying to understand whether or not theresone combination that actually magically generating the right set of representations in subsequent deeper layers such that your head can actually do the job so that is the first intuition regarding the incob so thats the first intuition regarding the increase in the depth of the of the of the filters"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "the second is that you can afford to i mean you can afford having that kindof increase in the depth of the filter and without really paying too much complexity performance"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "sorry complexity in the in the terms of number of operations because your special dimensions of the feature maps which are produced from a earlier operations are shrinking"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "so you increase the number of filter parameters and still youre not number of filter parameters and still youre not really paying any kind of complexity this sortof penalty because okay"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "so these are the two things that we need"
  },
  {
    "start": "-1:59:59.000000",
    "end": "-1:59:59.000000",
    "text": "we can actually mention about this kind d’architecture that looks again like a pyramid but this pyramid is a kind of works in  different way as as compared to what we have seen in fully connected architect pictures"
  },
  {
    "start": "00:39:13.630000",
    "end": "00:39:13.630000",
    "text": "and now i think its worthwhile spending some time on u on on an example and this example is — – a python notebookd this example is a python notebook this example is actually shown over here"
  },
  {
    "start": "00:39:16.430000",
    "end": "00:39:24.710000",
    "text": "you can actually click on this and open it in pap for execution however the notebook in your case over here will actually be working as it is"
  },
  {
    "start": "00:39:27.190000",
    "end": "00:39:27.190000",
    "text": "so in the next video well go through this example and then see exactly whats going on in terms of and the api and the implementation of a cnn"
  }
]