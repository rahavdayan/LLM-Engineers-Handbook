[
  {
    "start": "00:00:03.280000",
    "end": "00:00:34.350000",
    "text": "so this is basically what is happening in a an example over here where we have an input image and we are actually sliding a kernel a 3x3 kernel and we are getting an an aafeature map so the input feature map here is just has one we will be calling sometimes this depth channel and the output feature map has again one channel over here"
  },
  {
    "start": "00:00:38.229000",
    "end": "00:01:05.030000",
    "text": "and what we have here is we have a couple of things that we need to introduce as terms in convolutional operations that our actual doing and inside the convolutionthat we actually doing and inside the convolutional new networks so the first is the form of the concept of padding and typically we are padding the u input feature maps in order to do two things"
  },
  {
    "start": "00:01:09.270000",
    "end": "00:01:28.030000",
    "text": "we achieving two things perhaps you have noticed that in an earlier kindof discussion or we had the operation of cross correlation operation in this in this kind of image over here the output feature map was always smaller in terms of speciaals dimensions compared to the input feature map and it isdimensions compared to the input feature map and it is evidently so because"
  },
  {
    "start": "00:01:36.550000",
    "end": "00:02:16.470000",
    "text": "the only way that this output feature mk can be exactly the same size as the input is when the kernel is 1 by one so when the kel has a special extent of 1 by one then we have exactly that situation but in most cases where the can wont be onebyone we will expect this output feature maps to shrink in terms of spatial content and we do not want them to shrink too much because sooner or later we willbecause sooner or later we will be running out of spatial dimensions in our outputs and therefore we cannot really go deep to construct deep architectures in these networks"
  },
  {
    "start": "00:02:20.030000",
    "end": "00:02:41.390000",
    "text": "so what we expect to do is we have with padding we are trying to manage this special extent reduction on one hand as you can see if we had this padding over here then the output feature map is going to be much larger than otherwise so if you can imagine that without a padding then this sortof output feature mapwithout a padding then this sort of output feature map would actually be"
  },
  {
    "start": "00:02:59.550000",
    "end": "00:03:08.949000",
    "text": "i cant really sortof tell you exactly the dimensions but if you do it visually then you can actually see its going to be probably something like a 3x3 output now the sort of another advantage of padding is that we allow the kel to actually move into locations which would not be able to move otherwise"
  },
  {
    "start": "00:03:14.910000",
    "end": "00:03:30.990000",
    "text": "so – as we discussed a bit earlier — contains some values and we would like all earlier contains some values and we would like all of the pixels including the edge pixels of the input feature map to be able to be correlated with all of the other pixels of the allofthepixels of the kel and therefore padding allows us to do so"
  },
  {
    "start": "00:03:34.630000",
    "end": "00:04:11.910000",
    "text": "otherwise you can imagine this red kernel over here will actually be only be able to correlate with those three pixels of the input feature map now this pixel over here can be correlated with both this pixel of the kernel and that pixel of the andthis pixel of the kernel and that pixel of the and this pixel and this pixel of the sort of kel that we have so we have the ability to sortofget more information especially towards the edges of that input feature map with padding"
  },
  {
    "start": "00:04:14.949000",
    "end": "00:04:33.830000",
    "text": "another parameter that we should also sort of understand is this kind of stride so stride is the just like the stride that you as you walk it this here actually refers to the number of pixels that you are skipping over the in order for you to be ableorder for you to be ableto do the next correlation"
  },
  {
    "start": "00:04:39.310000",
    "end": "00:05:09.230000",
    "text": "so here you see two locations of that kernel in that location and the blue location the red location the blue location if your stride was one then the blue k have been right here and while with a stride of two then we dont get one correlation operation for every pixel of the input feature map and this is obviously is helping us manage the complexity of these filters"
  },
  {
    "start": "00:05:11.909000",
    "end": "00:05:33.710000",
    "text": "in fact goes slightly to the opposite direction of what we have said earlier in a opposite direction of what we have said earlier in a sense that in some instances we prefer to get for some of the layers of the convolutional neuron the stride parameter to be larger than one typically the strides parameter of height and width are going to be the same"
  },
  {
    "start": "00:05:36.629000",
    "end": "00:05:59.110000",
    "text": "so thats what you see over here bottom line is that all these parameters and far more that are to follow are hyperparameter optimization and we are going to be optimizing them for using hyperparameter optimization in order for ushyperparameter optimization in order for us to define the complete architecture of of a cnn here you see some animations that kindof reinforce what we have just quoted ed without padding"
  },
  {
    "start": "00:06:05.550000",
    "end": "00:06:26.710000",
    "text": "the kel the output feature map is going to be u potentially significantly reduced in terms of spatial extent something will make any subsequent cor correlation with kels you know not very useful with padding this is because we avoid that and here we actually have padding combinations of padding and stride"
  },
  {
    "start": "00:06:29.790000",
    "end": "00:07:00.270000",
    "text": "so i suggest that you combinations of padding and stride so i suggest that you study this kindof animations to just get the gist as to what padding and stride are actually offering to us but now the time has come to look at the operation of the convolutional neuron network and in fact the describe if you like the single convolutional kind in in detail we will start drawing a snapshot of a cnn layer operation that will actually help us to understand the general case where we have input u and output feature maps coming"
  },
  {
    "start": "00:07:09.390000",
    "end": "00:07:25.150000",
    "text": "and then so i am going to be using these kinds de conversion for an aewhere we have input u and output feature maps coming into the cnn layer but however these input and output feature maps possess different depths and this is another parameter that we have to understand you know that our we are responsible for designing these layers with that that the depth of what we will produce is our responsibility to to design"
  },
  {
    "start": "00:07:31.710000",
    "end": "00:07:53.270000",
    "text": "so letd write now draw if you like a a picture of that cnn layer in operation okay let me call it the the snapshot we will see just —snapshot we will see just a single snapshot of that layer and this will also help us understand the u what is the convolutional neuron we already have seen the sortofsigmoidal kind of neuroner"
  },
  {
    "start": "00:07:57.629000",
    "end": "00:08:05.430000",
    "text": "now well see in the inthe fully connected dense layer architectures now well see the convolutional neuroin front of us so the snapshot let me call it snapshot of a cnn of so lets draw now the general case as our discussed that you have an input volumethis input volume is associated withan input volume"
  },
  {
    "start": "00:08:33.399000",
    "end": "00:08:52.470000",
    "text": "this input volume is associated with h the output feature map of an earlier layer lets call that layer l  minus one this is basically the feature map that was generated by the previous layer in general and well have a depth of capital m  l  minus one it will have some kind de width let me make sure that you can actually see here"
  },
  {
    "start": "00:09:13.630000",
    "end": "00:09:36.150000",
    "text": "this is wl  minus one and the height over here would actually be okay this is a depth and the length over here will actually be h l – ‘motor’will actually be hlminus one all right so thats basically the dimensions of my incoming volume and this incoming volume has some kind resolution in terms of number of height and width pixels"
  },
  {
    "start": "00:09:43.150000",
    "end": "00:10:08.310000",
    "text": "let me just draw them quickly because we would like to now draw the u what will be the output of out of this operation which is the output feature map now the output is going to be generated at this specific moment in time i have in general a filter that has 3x3 special extent it is located lets say here at this particular moment in timespecial extent it is located"
  },
  {
    "start": "00:10:17.150000",
    "end": "00:10:40.079000",
    "text": "lets say here at this moment in time because thatso you call it a snapshot and it has some depth i want to discuss a little bit the depth what makes sense for this depth of the filter to be but it when it is located over here for sure im expecting to have some output feature map this output feature map will be probablysmaller in terms of spal extent"
  },
  {
    "start": "00:10:41.590000",
    "end": "00:10:41.590000",
    "text": "thats why ime kindof drawing it like this ofpixels okay and we have some kind of a depth and this depth is definitely something that i need to control because its oneof my main design parameters ill be calling this depth mml and evidently we have a different hl and wl dimensions and this is basically my"
  },
  {
    "start": "00:11:21.550000",
    "end": "00:11:35.710000",
    "text": "you know volumes input and output volumes in general going to have input and output fors so the question i actually have right now is to understand a little bit about the depth of the filter and our own and there are three options either aneop i this deep is definitely something that you want to controlsfilter and we have three options"
  },
  {
    "start": "00:11:39.030000",
    "end": "00:12:01.750000",
    "text": "whether the depth of the filter will actually be deeper than the input feature map shallower than the input feature map or exactly the same depth as the inputfeature maps so lets try to do some kind de reasoning over here does it make any sense for the filter to be deeper than the inputfactory map and if you think about it the answer is no"
  },
  {
    "start": "00:12:03.949000",
    "end": "00:12:29.829000",
    "text": "it does not really make a lot of sense because at the end of the day we are goingto be correlating that filters with to be correlating the contents of that filter with the contents of the input feature map and if the filter is actually deeper then we are not going to be picking up anything from the inputfeatured map because we are going to so why have it deeper"
  },
  {
    "start": "00:12:40.790000",
    "end": "00:13:17.189000",
    "text": "okay so you know theres no point of doing so if it is shallower than the inputfeature maps also it does not really make a lot of sense because we are goingto leave content that the inputfeature map u contains for us on the table so the so the only reasonablecontains for us on the table so the so the only reasonable assumption is this filter to be exactly the same in terms of the input feature map depth right in terms of this terms of depth of the input f map so its just basically draw it as such and it in fact it is really this filter that is going to be a going to be the one that we are going to be using to do this kindof a threedimensional kind of a correlation over here now to understand the contents of that correlation is kind of important andcontent of that correlation is kindof important"
  },
  {
    "start": "00:13:19.150000",
    "end": "00:13:31.189000",
    "text": "and what is actually even more important to understand what it will generate as we will see shortly what it will not generate it will not generate the whole volume over here but it will actually generate only one slice out of that output volume okay lets do the following let me take the sort of so for that specific snapshot that im actually right now"
  },
  {
    "start": "00:13:52.910000",
    "end": "00:14:25.269000",
    "text": "im generating thespecific let me draw that like theregenerating thespecific let me draw that like like there somespecific result which is a scaler therefore its a result of  a single pixel from this column which is located at the coordinate i comma j so specially wise and i hope you remember what we have seen earlier in the sort of example architecture"
  },
  {
    "start": "00:14:28.470000",
    "end": "00:15:03.069000",
    "text": "sorry in the cnn architecture diagram we are let just show you u that kind of diagram again for that specific snapshot lets say the blue la snapshot im actually reversing this scalar result and using justactually generating this scalar result and using just one kernel a filter of depth one in this case so as it will actually as it actually turns out that fil that filter at that specific snapshot it will do a threedimensional correlation and it will still generate a single scaler for me okay"
  },
  {
    "start": "00:15:09.509000",
    "end": "00:15:26.749000",
    "text": "and that single scalare will be at  a specific depth okay and the special coordinates of that scalaire is i comma j that the one i just drew now we will call that deep with an index in — but what i want to do herewith an index in a moment but what i want to do here is to just draw the complete column of pixels at icomma j location"
  },
  {
    "start": "00:15:34.790000",
    "end": "00:16:17.350000",
    "text": "let me just rotate them this column 90° and write it over here it will be evidently this dimension will be ml the depth dimension and this is the because we are correspond to the earth layer and let me just do exactly the same thing with the filter so ime actually taking the filter and decomposing it over here to the 3x3 kels that they contain and so these are going to be my3x3kennelscontains and so these are going to be my3x3kernels"
  },
  {
    "start": "00:16:22.230000",
    "end": "00:16:30.639000",
    "text": "and this will be of dimension mlminus1 so just took the filter rotated 90° and just decompos into its kels this is the lminus one layer and so since im going to be generating a scaler let’simply that ime generating right now at that specific snap sort the this is the icomma j coordinate this is the column that corresponds to the elayer andor generating this scalar over here this scalar is going to be represented by the letterz and well have evidently"
  },
  {
    "start": "00:17:15.630000",
    "end": "00:17:48.549000",
    "text": "i comma j as a special coordinates and we have  or equal to kl which i will designate with the letter kl and evidently 1 is less than or equal to kl is less than or equal to ml and this will actually be the values that the kl index which is the depth index can take and i will actually be using also an indepth coordination where each one of those kels which are going to be used for the plo and thereone of those kels which are going to be used for the determining that kind of scalar z so that scalar z is going to be produced by using all of the kelses of the the filter and i am going to also need to define to define two other indexes"
  },
  {
    "start": "00:18:18.029000",
    "end": "00:18:36.990000",
    "text": "the first index is going to be u and the second index goingto be v and this indices will actually be used to as spatial coordinates of the kernel okay so myequation so is the following so given i comma jcommas kl given in other words i comma soin other words the coordinates of the scalar which i want to generate my scalar zicomma jcommas kl are going to be given by three summations"
  },
  {
    "start": "00:18:55.510000",
    "end": "00:19:13.390000",
    "text": "the first two summations i have seen already in the plain twodimensional correlation operation the one that we just did in an ina earlier so this is usummation over uandv definitely ime expecting the special content of that kind de filter to be correlated and therefore dot product to take the dot product to take the input image okay"
  },
  {
    "start": "00:19:18.830000",
    "end": "00:19:39.149000",
    "text": "so this is the do not  scalarethe contents of the input image okay so this is the two summations over here but also ime expecting to now do a threedimensional correlation operation thats a third summation over an index ill be calling kl minus1 and this index addresses the specific kernel which im going to be using"
  },
  {
    "start": "00:19:44.110000",
    "end": "00:19:53.070000",
    "text": "so kl –  1 one is definitely the less than or equal to one and less than or equal to ml 1 one in — x of i  u j  v this kind of a correspondentthis kind of a correlation it will be x of i  u j  v comma kl1 time w where w now are the contents of the of the kernel that now has u kommas kl compama klminus1 all right"
  },
  {
    "start": "00:20:29.669000",
    "end": "00:20:39.789000",
    "text": "so we have in fact the w is not the cond of the kernel the conden of the kernel yes we can call them w but w i would associate w with this line over here that for specifying this line i have the ucomm a correspondence that specific kernel however is provided by this index is identified by this index"
  },
  {
    "start": "00:20:54.350000",
    "end": "00:21:03.430000",
    "text": "however is provided by this index is identified by this index so this specific kel is by this index and the scalar it is going to be generating is the located at the kl depth thats why i need this w of qcomma vcommas klcomma kl minus one okay so this will actually be the weights that are going be so a fourdimensional tensuror is being used here for specifying those parameters that that we are store in these in when they have only two filter right now so if you wantonly have one filter right now so a fourdimensional tensor to identify the parameters that we have used in this specific dot product over here"
  },
  {
    "start": "00:21:45.990000",
    "end": "00:22:13.430000",
    "text": "this is a threedimensional dot product and as you can imagine as im sliding the filter to another location in the next snapshot the only thing actually is changing is the space coordinate that is being produced in this scaler so the only thing so by moving the filter around im changing the i commas j of what im producing therefore what im actually going to be"
  },
  {
    "start": "00:22:14.870000",
    "end": "00:22:31.710000",
    "text": "im producing therefore what ime actually going to be producing is a slice a specific slice out of this sort of output feature map so the specific slice im just drawing over here just one of the ml slices so ml slices generates the complete volume so this slice is the one that i am going to be generating"
  },
  {
    "start": "00:22:53.909000",
    "end": "00:23:02.990000",
    "text": "this complete slice so effectively  a matrix and so from one filter ill be generating  single matrix and thereforeconclusion from we need multiple we need multipleoutput feature mapvolume so for a volume for the whole thing for the output feature map we need to be creating multiple fatures in fact this thing over here is really the connectivity diagram of the convolutional neuron"
  },
  {
    "start": "00:23:38.230000",
    "end": "00:24:15.510000",
    "text": "what we call a convolutional a single filter is and the operation actually we see over here is the operation of the convolutional neuron and this is all of these parameters that we have used over here the contents if you like the filters are from there is itused over here the contents if you like the filter are the socalled trainable parametersand we will now see an animation of this thing in in our core site so if i go to my core site and actually scroll down a little bit then you can see now the threedimensional"
  },
  {
    "start": "00:24:17.430000",
    "end": "00:24:32.789000",
    "text": "so first of all before we see the animation we can actually see its exactly the diagram i just drew a different i have an input volume which is the blue over here with has  has d in definitely as we mentioned the input sorry the filter that were going to be using has the same depth din as the input volume doesnt make sense otherwise and then on one slice lets say this specific matrix over here where my mouse pointer is"
  },
  {
    "start": "00:24:57.870000",
    "end": "00:25:07.549000",
    "text": "that is going to be what is going to be produced by a single filter and this dotted line here indicates that if you wantto generate the completeindicates that if you want to generate the complete output volume with a depth d out you need d out of these filters you need d out from these orange cubes in order for you to be ableto generate a complete green output feature map"
  },
  {
    "start": "00:25:25.909000",
    "end": "00:25:43.389000",
    "text": "so i think its worth spending some time in this animation in this animation you can actually see exactly what i just discussed here in this example i have an input feature map of depth three and i have output feature maps of depth two letd assume that that is the sortof of depth two lets assume that that is the sort of a design parameter which i want to implement"
  },
  {
    "start": "00:25:50.590000",
    "end": "00:26:08.110000",
    "text": "therefore if i have an output feat map of two i need two filters and these are the two filters this is the filter w0 and this is the filter w1 and evidently the each each of these filters has of dep depth three because three is also the depth of the input feature map and at every specific snapshot let’simply this is the snapshot that i just drew on pieceof paperpiece of paper"
  },
  {
    "start": "00:26:17.909000",
    "end": "00:27:04.070000",
    "text": "this filter is located at this specific location in my input feature map and it is responsible for creating this scalar z which is nine in this case okay so if i may and as far as the output feature map is concerned this filter is only able to plot if you like to determine the this specific slice of the output feature map if i want to continue then we will see that the second filter is the one which is involved in the creation of the second slice of the output featureof of the second slice of the output feature this is really the essence of a threedimensional convolution"
  },
  {
    "start": "00:27:07.830000",
    "end": "00:27:37.350000",
    "text": "i suggest that you spend some time on this animation trying to understand what is going on and you can toggle the movement just to be able to replicate the output scaler from the input values which have been provided overhere a bit on this presentation of the snapshot operation of — a layer the site over here has is squatting some kind of important formulas regarding the size the special"
  },
  {
    "start": "00:27:38.990000",
    "end": "00:28:13.029000",
    "text": "of important formulas regarding the size the special dimensions of the output feature map i think itseas important to note them down and so it is the floor of the height of the input feure map plus two  the padding size minus the kernel size divided by the strides and plus one okay so this is the formula that will that you can actually use to understand exactly what will be your output feature maps are in terms of spatial dimensions and of course this will be the inputfeature mapping sizes for the for thewill be the input feature map sizes for the forthelayer that follows"
  },
  {
    "start": "00:28:19.669000",
    "end": "00:28:36.990000",
    "text": "okay so what will actually be those layers i think its you know its quite important to get into the u discussion now about other architectural features before we go into some kind of a discussion about the advantages of convolution layers as compared to fully connected layers which i think is best demonstrated using an example"
  },
  {
    "start": "00:28:53.470000",
    "end": "00:28:57.710000",
    "text": "before we go into that example letd look at another operation that well be calling the max pulling layer oroperation that well be calling the maxstrength layer or in generalstrength layer which is actually described here and its best demonstrated with this kind of image and this this case what we see"
  },
  {
    "start": "00:29:03.789000",
    "end": "00:29:30.190000",
    "text": "we have an input feature map that has a depth of one in this case and we do still have the concept of if you like of a kernel that we slide around just like in the convolutional layer but in this case instead of a nonlinear function such as reu that we have actually also seen in the fully connected layers that we have actuallyactually also seen in the fully connected layers that we are still going to see in the evolutional layer as we will see"
  },
  {
    "start": "00:29:32.750000",
    "end": "00:29:32.750000",
    "text": "in that example we will have another function lets call that function in this specific case its shown as the max function wherethe idea behind this is that we are going not form a correlation result over here like  like dot product but were going to select the maximum element of what we see in the input feature map"
  },
  {
    "start": "00:29:56.630000",
    "end": "00:30:26.350000",
    "text": "typically we apply the that function at for each of these channels also on our ownapply the that function at for each of the channels of the input feature map but in some instances we may apply it also across the depth dimension what we are achieving is evidently we are achieving some reduction in the spatial dimensions of the output feature map and that kind of intuitively understood as trying to select the most important features of the inputfeature maps and transfer out into the layer above for further process"
  },
  {
    "start": "00:30:31.470000",
    "end": "00:30:45.310000",
    "text": "say okay so that is the max pooling layer in this case which isthat is the max pooling layer in this case which is typically interl with convolutional layers as we will see in some example architectures closing i want to emphasize the another u kind of specific parameterization of the convolutional layer"
  },
  {
    "start": "00:30:47.750000",
    "end": "00:31:14.269000",
    "text": "we call here the one by one convolutional layer and it is definitely a sortofa layer that it is being met in various kind of architect lectures and and maybe it does not really make a lot of sense to you the moment you see this kind of animation overmoment you see this kind of animation over here why in earth were going to do one by one convolutions since we as we discussed were trying to detect features and typically the kernel sizes have larger dimensions than onebyone"
  },
  {
    "start": "00:31:20.590000",
    "end": "00:31:31.149000",
    "text": "but i think the the explanation potentially could be more intuitively understood if we see the threedimensional version of this onebyone convolution so we have a see here the orange u filter that evidently is one by one and we have as we discussed earlier depth d you know when it comes to an occupation over there"
  },
  {
    "start": "00:31:41.350000",
    "end": "00:32:14.590000",
    "text": "by one and we have as we discussed earlier depth d that matches the depth of the input feature map and as we also discussed earlier the this filter operation will move around were sliding around this filter and wes creating one slice for this filter so in this one by one convolution we have just one slice and as you can see what we are achieving here we are forming a calar by combining the depth compressing the whole depth dimension"
  },
  {
    "start": "00:32:20.389000",
    "end": "00:32:31.310000",
    "text": "so we actually have we are seeing typically this typeactually have we are seeing typically this type of layers lets say towards the end of an network the top of the network where we just before the head where we want to just summarize everything we have done and then we just need to compress that information to a matrix and potentially that kindof slice is going to be flattened in order to be passed over into the head which may consistingto be passed over into the head which may consist of fully connected layers as well see that in a moment"
  },
  {
    "start": "00:33:00.190000",
    "end": "00:33:32.110000",
    "text": "okay so thats one application of the onebyone convol convolution operation all right so it it it kind of looks like an multilayer petron or a dense layer as it is combining these depth dimensionen into that scaler all right so letse now see some example architectures these example architectures could potentially be like the toy network that we have as we discussed the convolutionalhere where we have"
  },
  {
    "start": "00:33:34.710000",
    "end": "00:33:52.230000",
    "text": "as we discussed the convolutional layer followed by nonlinearity and max pulling layers and finally at the end we expect to see a fully connected layer that is going to play the role of the of the head of the network where we have lets say in this case five classes that we would like to do  a classification on"
  },
  {
    "start": "00:33:59.830000",
    "end": "00:34:39.069000",
    "text": "but instead of looking at this toy network work and i think its a bit more instructive to look at i will call it canonical architecture called vgg from the initials of thecanonical architecture called vgg from the initials of the authors of that kind of architecture this architecture is i call an architecture that i suggest students to start from every time they want to look at these convolutional networks because they do represent some kind of a initial good architecture that we can sortofmake some conclusions in regarding the dimensionality and the patterns that we expect to see in a typical cnn architecture instead of looking if you like in the most modern versionslooking if you like in the most modern versions of cnn i think its worthwhile looking at this to understand a couple"
  },
  {
    "start": "00:34:47.109000",
    "end": "00:35:04.630000",
    "text": "things so the first thing that wed like to capture over here is this image and understand what is really happening okay so the image is the in this figure we see a cnn layer so a cnn network that consist of multiple layers and one striking thing from the getgo that you can see is that the cnn is the dimensionality of the cnn is"
  },
  {
    "start": "00:35:13.670000",
    "end": "00:35:46.589000",
    "text": "in terms of spatial dimensionenterms of spatial dimensions is evidently shrinking as we are going deeper so we see the convolutional layers followed by max pulling layers u for and then towards the end we see the fully connected network which is the head so in terms of spatial dimensionsweets we are actually decreasing the spatial dimensions because obviously they are using kelses which are larger than one by one and and but on at the same time what we are also seeing is we see an increase in the depth dimension so in terms of numbers over"
  },
  {
    "start": "00:35:55.390000",
    "end": "00:36:15.230000",
    "text": "in the depth dimension so in terms of numbers over here 224x224 pixels are the spatial dimensions of the input images and then and then we have a 64 to be the depth dimension of the or equivalent the number of neurons in the u that we have in or the number of filters that we have in in that layer so this is also our responsibility"
  },
  {
    "start": "00:36:17.750000",
    "end": "00:36:40.470000",
    "text": "so our responsibility are twofold one is to with a padding and stride parameters to massage these kind of special dimensions we need and at the same time also select thewe need and at the same time also select the number of filters how many convolutional neurons are we going to engage in that layer so as you can see we go from 64 128 256 512"
  },
  {
    "start": "00:36:42.270000",
    "end": "00:36:59.710000",
    "text": "that is really the end game with respect to numberoffilters the intuition behind the increase in the number of filters as the network becomes deeper and deeper is the following the network is learning more and more complicated features as we are going deeper the first layers are the are are learning representations whichlayers are the are are learning representations which are simple shapes"
  },
  {
    "start": "00:37:05.230000",
    "end": "00:37:32.390000",
    "text": "i will call it similar things that you would expect to for you to understand when look at if you like at a kind of a primitive shape like  a circle a triangle or whatever have you and the subsequent kind of layers are actually learning more and more complicated representations well see in – — some examples of exactly what these layers are learning and by suitable visualizations so as you are trying to create combinations ofvisualisations"
  },
  {
    "start": "00:37:34.950000",
    "end": "00:37:53.950000",
    "text": "so as you are trying to create combinations of these simpler representations you probably need all to be doing more of those combinations as you go deeper because you are trying to understand whether or not theres one combination that actually magically generating the right set of representations in subsequent deeper layers such that your head can actually do the job"
  },
  {
    "start": "00:37:58.030000",
    "end": "00:38:15.630000",
    "text": "so that is the first intuition regarding the increase in the depth of the of the of the filters the second is that you can the of the of the filters the second is that you can afford to i mean you can afford having that kindof increase in the depth of the filter and without really paying too much complexity performance"
  },
  {
    "start": "00:38:20.309000",
    "end": "00:38:40.390000",
    "text": "sorry complexity in the in the terms of number of operations because your special dimensions of the feature maps which are produced from a earlier operations are shrinking so you increase the number of filter parameters and still youre not really paying any any complexity this sort of penalty because ofany any complexity"
  },
  {
    "start": "00:38:42.470000",
    "end": "00:38:48.910000",
    "text": "this sort of penalty because of that okay so these are the two things that we need we can actually mention about this kind architecture that looks again like a pyramid but this pyramid is and this example is  in fact its worth spending some time on u on an example you can actually click on this and now i think its worthwhile"
  },
  {
    "start": "00:39:16.430000",
    "end": "00:39:24.710000",
    "text": "you can actually click on this andshown over here you can actually click on this and open it in pap for execution however the notebook in your case over here will actually be working as it is so in the next video well go through this example and then see exactly whats going on in terms of and the api and the implementation of a cnn"
  }
]