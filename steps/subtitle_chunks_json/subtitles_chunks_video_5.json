[
  {
    "start": "00:00:00.000000",
    "end": "00:00:32.399000",
    "text": "in an earlier video we saw the structure of the convolutional neuron and how many of these neurons in the form  of filters are you know coming together to form a layer and how the multiple layers are coming again together stacked to implement this binary classification task in this video that we have looked at on cats versus dogs"
  },
  {
    "start": "00:00:32.399000",
    "end": "00:00:39.470000",
    "text": "now we will be using exactly the same model that we have built for that kind of task and in this specific case what we were interested now to see is to validate what we have said earlier about the some an earlier video i was looking at on cats vskind of a structure or pattern that we see in the features that the convolution un networks kindofread so in this notebook borrowed from the book deep learning with python what we actually can see a couple of things the first is the socalled u the intermediate convolution network outputs"
  },
  {
    "start": "00:00:39.470000",
    "end": "00:01:19.590000",
    "text": "these are effectively what are each layer kind of presents to the layer above it and i think its worthwhile kind of going through that first and as we said this is the sort of exactly the same architecture we have seen earlier for that specific data set and this is the input images the 100 approximately 150 by 150 pixels and natural reccol images"
  },
  {
    "start": "00:01:19.590000",
    "end": "00:01:56.880000",
    "text": "and this is the you know first layer what it really learns and as you can see the output of the output kinda feature map it kind of presents an almost identical figure to the sort  of input picture input image"
  },
  {
    "start": "00:01:56.880000",
    "end": "00:02:11.790000",
    "text": "except that this image over here emphasizes the edge so these are the as we said the primitive kind of shapes that the first initial layers of the conet are actually learning and we can actually go and lookat each and every layer and i think the over here i think this this im figure over here shows what is really happening so the initial layers are learning i will call it a visual content the same kind of visual content as our eyes kindofsee in the image"
  },
  {
    "start": "00:02:11.790000",
    "end": "00:02:19.750000",
    "text": "lets say you can very clearly see the shape and form of the of the cut over here but as we actually going further deeper into the network then the representations that are actually being created are becoming more and more abstract to the pointwhere this is the fifth layer as you can see from that point onwards we still see some of the feature maps that are being created"
  },
  {
    "start": "00:02:19.750000",
    "end": "00:02:47.990000",
    "text": "remember the feature maps that are being created are volumes so what actually we see here are the flattened version of those volumes so we plot here the special dimensions that are coming at at the output on each image but we are effectively flattening all of the filters that we have u used all of the allofthe depth of the feature maps that we have used to to create"
  },
  {
    "start": "00:02:47.990000",
    "end": "00:02:56.470000",
    "text": "this volume so here you have the sixth layer the seventh layer as you can see here we from the seventh layer onwards we are not really able to see any of the sort of visual characteristics of of a cut so this become  a fairly abstract kind of representation here you can actually also see very clearly the impact of max pooling and how we can actually start with a representation and what is the max pooling operator with cal of 2x two is actually doing"
  },
  {
    "start": "00:02:56.470000",
    "end": "00:03:03.589000",
    "text": "is actually picking at the more essential kindin features that are presented to it so if you compare this image and this image and so thats effectively"
  },
  {
    "start": "00:03:03.589000",
    "end": "00:03:25.120000",
    "text": "at this point we have the representations that are going to be needed after the stochasticrated descent kind of converges and provided we dont have any overfitting and so on these representations are the ones that we are going to be flattening to and then feed them into the fully connected layers that constitute our head and if everything goes okay this head will actually see and work on those representations to"
  },
  {
    "start": "00:03:25.120000",
    "end": "00:03:30.670000",
    "text": "actually do the binary classification okay so this is what we have seen we can actually see in the feature maps and i think its also worthwhile understanding what we actually see now in as far as the filters what really the contents of those filters are to visualize those filters what we actually do is we define a specific loss function"
  },
  {
    "start": "00:03:30.670000",
    "end": "00:03:32.840000",
    "text": "the details are kindof outside of this course of the scope of this course but the at  high level what we do is we try to find input images that maximize theactiverations that those filters produce and therefore in the process of doing so we are able to outof this optimization process to retrieve those filter values so here we see just the first 64 filters out of the many more that we have used i think we used all the way up to 256 filters but we here we see the first 64 filters in a 8 by8 kind of pattern"
  },
  {
    "start": "00:03:32.840000",
    "end": "00:03:39.390000",
    "text": "and as you can actually see the u this filter over here is for the various kind of layers so these are effectively we have the layers going from the beginning of this filof the the beginning of the network all the way to the u towards the just before the head of this"
  },
  {
    "start": "00:03:39.390000",
    "end": "00:03:59.030000",
    "text": "so this is the last layer just before the head and as you can actually see here in every layer we learn effectively a collection of these filters that it will decompose the input image the input the input the input feature maps are being decomposed so imagine that you have now not only one filter but also you have lets say 64 of them so the each one of those filters is one component out of the"
  },
  {
    "start": "00:03:59.030000",
    "end": "00:03:59.030000",
    "text": "lets say 64 that the input feature map will be deccomposed so you can read about this as those are the components of that decomposition so this so in the last kind  layer over here we have 64 components for those who have some background on principal component analysis"
  },
  {
    "start": "00:03:59.030000",
    "end": "00:04:33.710000",
    "text": "theres some something to it along those lines but the composition over here is definitely exactly the same as any other dekomposition its just that thesecomponents as the layers are becoming deeper and deeper are these components are are you know look quite different and this as you can see here the filters are simpler in the first layers and become more and more complicated in the subsequent kind of layers to match the sort of nonv visual intuitively visual complexities that we have seen in the output activation maps or feature maps that we have seen earlier"
  }
]