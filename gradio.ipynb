{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61eb3768",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-06 04:11:41.178312: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746519101.193900  123631 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746519101.198547  123631 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746519101.210525  123631 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746519101.210544  123631 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746519101.210546  123631 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746519101.210548  123631 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-06 04:11:41.214571: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([{'role': 'user',\n",
       "   'content': 'Using only the videos, explain how ResNets work.'},\n",
       "  {'role': 'assistant',\n",
       "   'content': 'Here are the requested steps:\\n\\n**1. Summarize the main idea or key point explained in the question:**\\nThe user wants an explanation of how ResNets work based on video content.\\n\\n**2. Highlight any explanation, definition, or key information related to the user\\'s question:**\\nUnfortunately, there is not enough text provided to highlight specific explanations or definitions directly related to \"how ResNets work\". However, I can infer that the mention of an \"example\" and \"implementation of acn (a type of neural network architecture)\" might be relevant.\\n\\n**3. If relevant, rephrase technical descriptions into simpler or more understandable terms:**\\nTo simplify the explanation, we could say that a ResNet is a type of deep learning model that uses a special way to connect its layers to help it learn features from images and other data more effectively. However, this simplification relies on general knowledge about neural networks and might not directly relate to the user\\'s question based on the provided text snippet.\\n\\nIf you\\'d like me to review additional text or provide further assistance, please let me know!'}],\n",
       " None)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "from retrieval import *\n",
    "\n",
    "\n",
    "# Chatbot function\n",
    "def chatbot_interface(user_input):\n",
    "    # Generate text response and relevant video segment\n",
    "    chunks = grab_relevant_chunks(user_input)  # Generate text response\n",
    "    video_segment_path = None\n",
    "    text = \"\"\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        video_idx = chunk[\"video\"]\n",
    "        start = chunk[\"start\"]\n",
    "        end = chunk[\"end\"]\n",
    "        text = chunk[\"text\"]\n",
    "        try:\n",
    "            video_segment_path = get_video_segment(start, end, video_idx)\n",
    "        except:\n",
    "            video_segment_path = None\n",
    "    \n",
    "    chat_history = [\n",
    "        {\"role\": \"user\", \"content\": user_input},\n",
    "        {\"role\": \"assistant\", \"content\": generate_response(user_input, text)}\n",
    "    ]\n",
    "    return (chat_history, video_segment_path)\n",
    "\n",
    "# Interface elements\n",
    "with gr.Blocks(title=\"Video-Based Q&A Bot\") as iface:\n",
    "    gr.Markdown(\"## Ask any question about video content and get answers based on the video segments.\")\n",
    "    user_input = gr.Textbox(label=\"Ask a Question\", placeholder=\"Type your question here...\", lines=1)\n",
    "    submit_btn = gr.Button(\"Submit Question\")\n",
    "    chatbot_output = gr.Chatbot(label=\"Chatbot\", type=\"messages\")\n",
    "    video_output = gr.Video()\n",
    "\n",
    "    # Set button click to trigger chatbot\n",
    "    submit_btn.click(fn=chatbot_interface, inputs=user_input, outputs=[chatbot_output, video_output])\n",
    "\n",
    "iface.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-engineering-sRZUHTNH-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
